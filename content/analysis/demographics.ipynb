{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/tt/j3zywfxn4s364d1pj12scs_r0000gq/T//Rtmpah7fVo/downloaded_packages\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/tt/j3zywfxn4s364d1pj12scs_r0000gq/T//Rtmpah7fVo/downloaded_packages\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/tt/j3zywfxn4s364d1pj12scs_r0000gq/T//Rtmpah7fVo/downloaded_packages\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/tt/j3zywfxn4s364d1pj12scs_r0000gq/T//Rtmpah7fVo/downloaded_packages\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/tt/j3zywfxn4s364d1pj12scs_r0000gq/T//Rtmpah7fVo/downloaded_packages\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/tt/j3zywfxn4s364d1pj12scs_r0000gq/T//Rtmpah7fVo/downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependencies ‘estimability’, ‘numDeriv’, ‘mvtnorm’\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/tt/j3zywfxn4s364d1pj12scs_r0000gq/T//Rtmpah7fVo/downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Welcome to emmeans.\n",
      "NOTE -- Important change from versions <= 1.41:\n",
      "    Indicator predictors are now treated as 2-level factors by default.\n",
      "    To revert to old behavior, use emm_options(cov.keep = character(0))\n",
      "\n",
      "\n",
      "Attaching package: ‘reshape2’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    smiths\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"ggridges\")\n",
    "install.packages(\"reshape2\")\n",
    "install.packages(\"tidyverse\")\n",
    "install.packages(\"magrittr\")\n",
    "install.packages(\"broom\")\n",
    "install.packages(\"FactoMineR\")\n",
    "install.packages(\"emmeans\")\n",
    "\n",
    "library(tidyverse)\n",
    "library(magrittr)\n",
    "library(broom)\n",
    "library(FactoMineR)\n",
    "library(emmeans)\n",
    "library(ggridges)\n",
    "library(reshape2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data, scripts\n",
    "pca_labels.rda is old. You could update it with the new labels in place if you want using the structure of pca_labels.rda. I filled in the table in google sheets, then exported it as a csv, loaded it into R, and then resaved it as a RDA file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load('./data/merged_artsengagement.rda')\n",
    "load('./data/tidy_questions_best.Rda')\n",
    "source('./scripts/select_helpers.R')\n",
    "load('./data/pca_labels.rda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all factors vvv\n",
    "# df[df %>% sapply(is.factor) %>% as.vector, rownums]\n",
    "motiv_demos <- df %>% select(contains('sr_motivation')) %>% names\n",
    "identity_demos <- df %>% select(contains('sr_identity')) %>% names\n",
    "participation_demos <- df %>% select(all_arts('participation')) %>% select(starts_with('sr')) %>% names\n",
    "real_demos <- c('ethnic_group', 'sex', 'school', 'parented', 'income', 'artsincollege', 'hstype', 'hssize',\n",
    "           'hslocation', 'hs_arts_freq', 'hs_encouragement', 'hs_required', 'hs_fees',\n",
    "           'so_childhood1', 'so_childhood3', 'so_childhood5', 'sr_participated',\n",
    "               'sr_highestdegreeplanned')\n",
    "demo_groups <- c('real_demos','motiv_demos','identity_demos','participation_demos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripnames <- function(data, question) {\n",
    "    data <- data %>% select('rownums', starts_with(question))\n",
    "    varnames <- names(data)\n",
    "    newnames <- varnames\n",
    "    for (i in seq(3, length(varnames))) {\n",
    "        newnames[i] <- substr(varnames[i], gregexpr(\"\\\\.\\\\.\", varnames[i])[[1]][1]+2, nchar(varnames[i]))\n",
    "    }\n",
    "    names(data) <- newnames\n",
    "    return(data)\n",
    "}\n",
    "\n",
    "stripVars <- function(data) {\n",
    "    #remove irrelavant variables\n",
    "    removenames <- names(data %>% select(matches(\"AIC..Words|AIC..IC_Differentiation|AIC..IC_Integration|AIC..DIAL_Differentiation|AIC..DIAL_Integration|AIC..ELAB_Differentiation|AIC..ELAB_Integration|docuscope..OralCues|docuscope..DialogCues|docuscope..XWordTokens|docuscope..XPunctuationTokens|docuscope..XTokens|LIWC..WC|LIWC..Sixltr|LIWC..Dic|LIWC..WPS|LIWC..swear|LIWC..netspeak|LIWC..assent|LIWC..nonflu|LIWC..filler|LIWC..AllPunc|LIWC..Period|LIWC..Comma|LIWC..Colon|LIWC..SemiC|LIWC..QMark|LIWC..Exclam|LIWC..Dash|LIWC..Quote|LIWC..Apostro|LIWC..Parenth|LIWC..OtherP\")))\n",
    "    data <- data[ , !names(data) %in% removenames]\n",
    "    return(data)\n",
    "}\n",
    "\n",
    "mergeQuestion <- function(data, question) {\n",
    "    if (substr(question, 3,3) == '_') {\n",
    "        question <- substr(question, 4, nchar(question))\n",
    "    }\n",
    "    # if you're aware of other prefixes, add them here\n",
    "    yrs <- c(NA,'fl','f1','f2','so','jr','sr','sl')\n",
    "    data$rownums <- seq(nrow(data)) # add rownums so resulting data can be re-integrated\n",
    "    mergeddf <- data.frame()\n",
    "    for (yr in yrs) {\n",
    "        if (question == 'definition' && is.na(yr))\n",
    "            qyr <- question\n",
    "        else if (is.na(yr))\n",
    "            next\n",
    "        else {\n",
    "            qyr <- paste0(yr, '_', question)\n",
    "        }\n",
    "        if (data %>% select(starts_with(qyr)) %>% ncol == 0) { next }\n",
    "        tempdf <- stripnames(data, qyr)\n",
    "        names(tempdf)[2] <- question\n",
    "        mergeddf <- bind_rows(mergeddf, tempdf)        \n",
    "    }\n",
    "    mergeddf <- mergeddf[complete.cases(mergeddf),]\n",
    "    mergeddf <- mergeddf %>% stripVars\n",
    "    rownames(mergeddf) <- c()\n",
    "    return(mergeddf)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alt temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp <- demodfpcs %>% select(-matches(paste0('PC[',paste0(seq(5)[seq(5)!=p], collapse = ''),']')))\n",
    "names(temp)[ncol(temp)] <- 'pc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_contrasts.demos <- c()\n",
    "sig_aov_posthoc <- c()\n",
    "dir.create('./results', showWarnings = F)\n",
    "for(question in question_names[-c(4:6,9:14)]) {\n",
    "    # directories\n",
    "    dir.create(paste('./results', question, sep = '/'), showWarnings = F)\n",
    "    \n",
    "    # data subsetting, PC\n",
    "    data_subset <- mergeQuestion(df, question)\n",
    "    data_subset_rows <- data_subset[[1]]\n",
    "    data_subset <- data_subset[-1]\n",
    "    data_subset <- data_subset[-1]\n",
    "    percent <- 0.4\n",
    "    data_subset <- data_subset[ lapply( data_subset, function(x) sum(x==0) / length(x) ) < percent ]\n",
    "    pd <- prcomp(data_subset, retx= TRUE, center=TRUE, scale=TRUE)\n",
    "\n",
    "    # merge with demographic cols\n",
    "    pcs <- data.frame(rownum = data_subset_rows, pd$x[,seq(5)] %>% as.data.frame)\n",
    "    rownums <- pcs$rownum %>% sort\n",
    "    pcs <- pcs %>% arrange(rownum)\n",
    "    pcs <- pcs[-1]\n",
    "    demodfpcs <- bind_cols(df[rownums,c('key',real_demos)], pcs)\n",
    "\n",
    "    # weighting by # of responses per respondent\n",
    "    resps_by_key <- demodfpcs$key %>% table %>% as.data.frame\n",
    "    names(resps_by_key) <- c('key','n')\n",
    "    resps_by_key %<>% filter(n!=0)\n",
    "    for(r in seq(nrow(demodfpcs))) {\n",
    "        nresps <- resps_by_key %>% filter(key == demodfpcs[r,]$key) %>% .$n\n",
    "        demodfpcs[r, names(select(demodfpcs,matches('PC[12345]')))] <- (1/nresps) *\n",
    "                                                            (demodfpcs[r, names(select(demodfpcs,matches('PC[12345]')))])\n",
    "    }\n",
    "    demodfpcs <- demodfpcs %>% select(-'key')\n",
    "    demodf <- demodfpcs %>% select(-matches('PC[12345]'))\n",
    "    pcs <- demodfpcs %>% select(matches('PC[12345]'))\n",
    "\n",
    "    # analysis\n",
    "    for(p in seq(pcs)) {\n",
    "        # directories\n",
    "        dir.create(paste('./results', question, names(pcs)[p], sep = '/'), showWarnings = F)\n",
    "        dir.create(paste('./results', question, names(pcs)[p], 'emmeans', sep = '/'), showWarnings = F)\n",
    "        dir.create(paste('./results', question, names(pcs)[p], 'anova_tukey', sep = '/'), showWarnings = F)\n",
    "        for(d in seq(demodf)) {\n",
    "            temp <- bind_cols(pcs[p], demodf[d])\n",
    "            names(temp) <- c('pc','demo')\n",
    "            if((temp$demo %>% table %>% as.data.frame %>% filter(Freq != 0) %>% nrow) == 1) next\n",
    "\n",
    "            # emmeans contrasts\n",
    "            lm.out <- lm(pc ~ demo, data=temp, na.action = na.exclude)\n",
    "            em.out <- emmeans(lm.out, ~ demo, data=temp, weights = 'proportional')\n",
    "            contrast.out <- contrast(em.out, method=\"del.eff\") %>% tidy\n",
    "\n",
    "            contrast.out$p.value %<>% p.adjust(method='holm')\n",
    "            contrast.out %<>% mutate(question_name=question,\n",
    "                                        PC_num = paste0('PC',p), \n",
    "                                        PC_pos = pca_labels %>% \n",
    "                                                  filter(question_name==question) %>% \n",
    "                                                  select(matches(paste0(p,'_pos'))) %>%\n",
    "                                                  pull %>% as.character,\n",
    "                                        PC_neg = pca_labels %>% \n",
    "                                                  filter(question_name==question) %>% \n",
    "                                                  select(matches(paste0(p,'_neg'))) %>%\n",
    "                                                  pull %>% as.character,\n",
    "                                        demographic = names(demodf)[d]\n",
    "                                     )            \n",
    "\n",
    "            # anova tukey\n",
    "            aov.out <- aov(pc ~ demo, data=temp) %>% TukeyHSD %>% tidy\n",
    "            aov.out %<>% select(-term) %>% mutate(question_name=question,\n",
    "                                        PC_num = paste0('PC',p), \n",
    "                                        PC_pos = pca_labels %>% \n",
    "                                                  filter(question_name==question) %>% \n",
    "                                                  select(matches(paste0(p,'_pos'))) %>%\n",
    "                                                  pull %>% as.character,\n",
    "                                        PC_neg = pca_labels %>% \n",
    "                                                  filter(question_name==question) %>% \n",
    "                                                  select(matches(paste0(p,'_neg'))) %>%\n",
    "                                                  pull %>% as.character,\n",
    "                                        demographic = names(demodf)[d]\n",
    "                                     )\n",
    "            \n",
    "            # bind rows\n",
    "            options(warn=-1)\n",
    "            sig_contrasts.demos %<>% bind_rows(contrast.out)\n",
    "            sig_aov_posthoc %<>% bind_rows(aov.out)\n",
    "            options(warn=0)\n",
    "            \n",
    "            # write csvs\n",
    "            write.csv(contrast.out, paste('./results',question,names(pcs)[p],'emmeans',paste0(names(demodf)[d],'.csv'),sep='/'))\n",
    "            write.csv(aov.out, paste('./results',question,names(pcs)[p],'anova_tukey',paste0(names(demodf)[d],'.csv'),sep='/'))\n",
    "        }\n",
    "    }\n",
    "}\n",
    "# # write rdas\n",
    "save(sig_contrasts.demos, file='./results/emmeans_contrasts.rda')\n",
    "save(sig_aov_posthoc, file='./results/anova_tukey.rda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## begin tidy graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_demos <- c('ethnic_group', 'sex', 'school', 'parented', 'income', 'artsincollege', 'hstype', 'hssize',\n",
    "           'hslocation', 'hs_arts_freq', 'hs_encouragement', 'hs_required', 'hs_fees',\n",
    "           'so_childhood1', 'so_childhood3', 'so_childhood5', 'sr_participated',\n",
    "               'sr_highestdegreeplanned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripnames <- function(data, question) {\n",
    "    data <- data %>% select('rownums', starts_with(question))\n",
    "    varnames <- names(data)\n",
    "    newnames <- varnames\n",
    "    for (i in seq(3, length(varnames))) {\n",
    "        newnames[i] <- substr(varnames[i], gregexpr(\"\\\\.\\\\.\", varnames[i])[[1]][1]+2, nchar(varnames[i]))\n",
    "    }\n",
    "    names(data) <- newnames\n",
    "    return(data)\n",
    "}\n",
    "\n",
    "stripVars <- function(data) {\n",
    "    #remove irrelavant variables\n",
    "    removenames <- names(data %>% select(matches(\"AIC..Words|AIC..IC_Differentiation|AIC..IC_Integration|AIC..DIAL_Differentiation|AIC..DIAL_Integration|AIC..ELAB_Differentiation|AIC..ELAB_Integration|docuscope..OralCues|docuscope..DialogCues|docuscope..XWordTokens|docuscope..XPunctuationTokens|docuscope..XTokens|LIWC..WC|LIWC..Sixltr|LIWC..Dic|LIWC..WPS|LIWC..swear|LIWC..netspeak|LIWC..assent|LIWC..nonflu|LIWC..filler|LIWC..AllPunc|LIWC..Period|LIWC..Comma|LIWC..Colon|LIWC..SemiC|LIWC..QMark|LIWC..Exclam|LIWC..Dash|LIWC..Quote|LIWC..Apostro|LIWC..Parenth|LIWC..OtherP\")))\n",
    "    data <- data[ , !names(data) %in% removenames]\n",
    "    return(data)\n",
    "}\n",
    "\n",
    "mergeQuestion <- function(data, question) {\n",
    "    if (substr(question, 3,3) == '_') {\n",
    "        question <- substr(question, 4, nchar(question))\n",
    "    }\n",
    "    # if you're aware of other prefixes, add them here\n",
    "    yrs <- c(NA,'fl','f1','f2','so','jr','sr','sl')\n",
    "    data$rownums <- seq(nrow(data)) # add rownums so resulting data can be re-integrated\n",
    "    mergeddf <- data.frame()\n",
    "    for (yr in yrs) {\n",
    "        if (question == 'definition' && is.na(yr))\n",
    "            qyr <- question\n",
    "        else if (is.na(yr))\n",
    "            next\n",
    "        else {\n",
    "            qyr <- paste0(yr, '_', question)\n",
    "        }\n",
    "        if (data %>% select(starts_with(qyr)) %>% ncol == 0) { next }\n",
    "        tempdf <- stripnames(data, qyr)\n",
    "        names(tempdf)[2] <- question\n",
    "        mergeddf <- bind_rows(mergeddf, tempdf)        \n",
    "    }\n",
    "    mergeddf <- mergeddf[complete.cases(mergeddf),]\n",
    "    mergeddf <- mergeddf %>% stripVars\n",
    "    rownames(mergeddf) <- c()\n",
    "    return(mergeddf)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "question <- question_names[-c(4:6,9:14)][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data subsetting, PC\n",
    "data_subset <- mergeQuestion(df, question)\n",
    "data_subset_rows <- data_subset[[1]]\n",
    "data_subset <- data_subset[-1]\n",
    "data_subset <- data_subset[-1]\n",
    "percent <- 0.4\n",
    "data_subset <- data_subset[ lapply( data_subset, function(x) sum(x==0) / length(x) ) < percent ]\n",
    "pd <- prcomp(data_subset, retx= TRUE, center=TRUE, scale=TRUE)\n",
    "\n",
    "# merge with demographic cols\n",
    "pcs <- data.frame(rownum = data_subset_rows, pd$x[,seq(5)] %>% as.data.frame)\n",
    "rownums <- pcs$rownum %>% sort\n",
    "pcs <- pcs %>% arrange(rownum)\n",
    "pcs <- pcs[-1]\n",
    "demodfpcs <- bind_cols(df[rownums,c('key',real_demos)], pcs)\n",
    "\n",
    "# weighting by # of responses per respondent\n",
    "resps_by_key <- demodfpcs$key %>% table %>% as.data.frame\n",
    "names(resps_by_key) <- c('key','n')\n",
    "resps_by_key %<>% filter(n!=0)\n",
    "for(r in seq(nrow(demodfpcs))) {\n",
    "    nresps <- resps_by_key %>% filter(key == demodfpcs[r,]$key) %>% .$n\n",
    "    demodfpcs[r, names(select(demodfpcs,matches('PC[12345]')))] <- (1/nresps) *\n",
    "                                                        (demodfpcs[r, names(select(demodfpcs,matches('PC[12345]')))])\n",
    "}\n",
    "demodfpcs <- demodfpcs %>% select(-'key')\n",
    "demodf <- demodfpcs %>% select(-matches('PC[12345]'))\n",
    "pcs <- demodfpcs %>% select(matches('PC[12345]'))\n",
    "\n",
    "# analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter demographics to those within min & max levels (inclusive) into small_demos variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'ethnic_group'</li>\n",
       "\t<li>'sex'</li>\n",
       "\t<li>'school'</li>\n",
       "\t<li>'parented'</li>\n",
       "\t<li>'income'</li>\n",
       "\t<li>'artsincollege'</li>\n",
       "\t<li>'hstype'</li>\n",
       "\t<li>'hssize'</li>\n",
       "\t<li>'hslocation'</li>\n",
       "\t<li>'hs_arts_freq'</li>\n",
       "\t<li>'hs_encouragement'</li>\n",
       "\t<li>'hs_required'</li>\n",
       "\t<li>'hs_fees'</li>\n",
       "\t<li>'so_childhood1'</li>\n",
       "\t<li>'so_childhood3'</li>\n",
       "\t<li>'so_childhood5'</li>\n",
       "\t<li>'sr_participated'</li>\n",
       "\t<li>'sr_highestdegreeplanned'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'ethnic\\_group'\n",
       "\\item 'sex'\n",
       "\\item 'school'\n",
       "\\item 'parented'\n",
       "\\item 'income'\n",
       "\\item 'artsincollege'\n",
       "\\item 'hstype'\n",
       "\\item 'hssize'\n",
       "\\item 'hslocation'\n",
       "\\item 'hs\\_arts\\_freq'\n",
       "\\item 'hs\\_encouragement'\n",
       "\\item 'hs\\_required'\n",
       "\\item 'hs\\_fees'\n",
       "\\item 'so\\_childhood1'\n",
       "\\item 'so\\_childhood3'\n",
       "\\item 'so\\_childhood5'\n",
       "\\item 'sr\\_participated'\n",
       "\\item 'sr\\_highestdegreeplanned'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'ethnic_group'\n",
       "2. 'sex'\n",
       "3. 'school'\n",
       "4. 'parented'\n",
       "5. 'income'\n",
       "6. 'artsincollege'\n",
       "7. 'hstype'\n",
       "8. 'hssize'\n",
       "9. 'hslocation'\n",
       "10. 'hs_arts_freq'\n",
       "11. 'hs_encouragement'\n",
       "12. 'hs_required'\n",
       "13. 'hs_fees'\n",
       "14. 'so_childhood1'\n",
       "15. 'so_childhood3'\n",
       "16. 'so_childhood5'\n",
       "17. 'sr_participated'\n",
       "18. 'sr_highestdegreeplanned'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"ethnic_group\"            \"sex\"                    \n",
       " [3] \"school\"                  \"parented\"               \n",
       " [5] \"income\"                  \"artsincollege\"          \n",
       " [7] \"hstype\"                  \"hssize\"                 \n",
       " [9] \"hslocation\"              \"hs_arts_freq\"           \n",
       "[11] \"hs_encouragement\"        \"hs_required\"            \n",
       "[13] \"hs_fees\"                 \"so_childhood1\"          \n",
       "[15] \"so_childhood3\"           \"so_childhood5\"          \n",
       "[17] \"sr_participated\"         \"sr_highestdegreeplanned\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min = 2\n",
    "max = 24\n",
    "temp <- demodfpcs %>% sapply(function(x)(x %>% levels %>% length)) %>% as.data.frame\n",
    "temp$demo <- rownames(temp)\n",
    "temp <- temp %>% filter(. >= min & max >= .)\n",
    "small_demos <- temp %>% pull(demo)\n",
    "small_demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over all questions, generating PCs, munging their data, and finally generating graphs for them all\n",
    "I recommend letting the code run for say 10 seconds then hit i twice to stop it to then print out / explore the variables being used within the ggplot code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n",
      "Warning message:\n",
      "“Groups with fewer than two data points have been dropped.”\n"
     ]
    }
   ],
   "source": [
    "dir_to_save_results = './results-jan'\n",
    "plot_type = 'violin_plots' # plural\n",
    "output_format = '.pdf' # with dot\n",
    "\n",
    "dir.create(dir_to_save_results, showWarnings = F)\n",
    "# for all stm'd questions\n",
    "for(question in question_names[-c(4:6,9:14)]) {\n",
    "    dir.create(paste(dir_to_save_results, question, sep = '/'), showWarnings = F)\n",
    "    \n",
    "    # data subsetting, PC creation\n",
    "    data_subset <- mergeQuestion(df, question)\n",
    "    data_subset_rows <- data_subset[[1]]\n",
    "    data_subset <- data_subset[-1]\n",
    "    data_subset <- data_subset[-1]\n",
    "    percent <- 0.4\n",
    "    data_subset <- data_subset[ lapply( data_subset, function(x) sum(x==0) / length(x) ) < percent ]\n",
    "    pd <- prcomp(data_subset, retx= TRUE, center=TRUE, scale=TRUE)\n",
    "\n",
    "    # merge PCs with demographic cols\n",
    "    pcs <- data.frame(rownum = data_subset_rows, pd$x[,seq(5)] %>% as.data.frame)\n",
    "    rownums <- pcs$rownum %>% sort\n",
    "    pcs <- pcs %>% arrange(rownum)\n",
    "    pcs <- pcs[-1]\n",
    "    demodfpcs <- bind_cols(df[rownums,c('key',real_demos)], pcs)\n",
    "\n",
    "    # weighting by # of responses per respondent\n",
    "    resps_by_key <- demodfpcs$key %>% table %>% as.data.frame\n",
    "    names(resps_by_key) <- c('key','n')\n",
    "    resps_by_key %<>% filter(n!=0)\n",
    "    for(r in seq(nrow(demodfpcs))) {\n",
    "        nresps <- resps_by_key %>% filter(key == demodfpcs[r,]$key) %>% .$n\n",
    "        demodfpcs[r, names(select(demodfpcs,matches('PC[12345]')))] <- (1/nresps) *\n",
    "                                                        (demodfpcs[r, names(select(demodfpcs,matches('PC[12345]')))])\n",
    "    }\n",
    "                                       \n",
    "    # separate PCs and demographics\n",
    "    demodfpcs <- demodfpcs %>% select(-'key')\n",
    "    demodf <- demodfpcs %>% select(-matches('PC[12345]'))\n",
    "    pcs <- demodfpcs %>% select(matches('PC[12345]'))\n",
    "\n",
    "                  \n",
    "    # plotting (by PC)\n",
    "    for(p in seq(pcs)) {\n",
    "        # combine individual PC with demographics\n",
    "        temp <- bind_cols(pcs[p], demodf)\n",
    "        names(temp) <- c(\"pc\", names(temp)[-1])\n",
    "        \n",
    "        \n",
    "        # for each demographic...\n",
    "        for(d in seq(small_demos)) {\n",
    "            mu <- temp %>% na.omit %>% group_by_at(vars(small_demos[d])) %>% \n",
    "                summarise(grp.median=median(pc), grp.mean=mean(pc), grp.sd=sd(pc))\n",
    "#density plot\n",
    "               ggplot(na.omit(demodfpcs), aes_string(x=names(pcs)[p], fill=small_demos[d], color=small_demos[d])) +\n",
    "              #  geom_density_ridges(position='identity', alpha=.2) +\n",
    "               geom_density(position='identity', alpha=.2) +\n",
    "                \n",
    "   #violin_plot         \n",
    "            #g <- ggplot(na.omit(demodfpcs), aes_string(x=names(pcs)[p], y=small_demos[d]))\n",
    "            #g + geom_violin(scale=\"area\") + \n",
    "\n",
    "                xlim(round(na.omit(pcs[[p]]) %>% summary %>% tidy %>% .$minimum)-0.5, \n",
    "                     round(na.omit(pcs[[p]]) %>% summary %>% tidy %>% .$maximum)+.5) +\n",
    "                geom_vline(data=mu, aes_string(xintercept='grp.median', color=names(mu)[1]),\n",
    "                         linetype=\"dashed\") +\n",
    "                labs(subtitle=paste0('pos-x: ', pca_labels %>% \n",
    "                      filter(question_name==question) %>% \n",
    "                      select(matches(paste0(p,'_pos'))) %>%\n",
    "                      pull %>% as.character,\n",
    "                     '\\nneg-x: ', pca_labels %>% \n",
    "                      filter(question_name==question) %>% \n",
    "                      select(matches(paste0(p,'_neg'))) %>%\n",
    "                      pull %>% as.character)) +\n",
    "                theme(plot.subtitle = element_text(size=10))\n",
    "\n",
    "            # saving\n",
    "            dir.create(paste(dir_to_save_results, question, names(pcs)[p], sep='/'), showWarnings = F)\n",
    "            dir.create(paste(dir_to_save_results, question, names(pcs)[p], plot_type,sep='/'), showWarnings = F)\n",
    "            ggsave(paste(dir_to_save_results, question, names(pcs)[p], plot_type, \n",
    "                         paste0(small_demos[d], output_format),sep='/'), \n",
    "                   width = 6, height=5)\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'PC5'"
      ],
      "text/latex": [
       "'PC5'"
      ],
      "text/markdown": [
       "'PC5'"
      ],
      "text/plain": [
       "[1] \"PC5\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(pcs)[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in ggplot(summaryValues, aes(factor(Discipline), y = pointEst, ymin = minCI, : object 'summaryValues' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in ggplot(summaryValues, aes(factor(Discipline), y = pointEst, ymin = minCI, : object 'summaryValues' not found\nTraceback:\n",
      "1. ggplot(summaryValues, aes(factor(Discipline), y = pointEst, ymin = minCI, \n .     ymax = maxCI, color = factor(Discipline), shape = factor(SigEff, \n .         labels = c(\"Not Sig.\", \"p <= .05\"))))"
     ]
    }
   ],
   "source": [
    "ggplot(summaryValues,aes(factor(Discipline), y = pointEst , ymin = minCI, ymax = maxCI,\n",
    "          color=factor(Discipline), shape=factor(SigEff, labels = c(\"Not Sig.\", \"p <= .05\")))) +\n",
    "          geom_pointrange() + facet_wrap(~Topic, shrink = TRUE, as.table = TRUE, labeller = topic_labels_panel) + \n",
    "          theme(legend.justification = \"top\", axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank()) + \n",
    "           scale_colour_manual(name=\"Primary Discipline\", values=a2ru) + scale_shape_manual(name=\"Significant Difference?\", values = c(19,8)) + labs(y = \"Proportion\") +\n",
    "           labs(title = \"Topical Prevalence Plot across Different Topics\") \n",
    "    ggsave(paste(folder_id, q_id, \"TopicPrevByTopic.pdf\", sep = \"\"), width = width, height = height, useDingbats=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'ethnic_group'</li>\n",
       "\t<li>'sex'</li>\n",
       "\t<li>'school'</li>\n",
       "\t<li>'parented'</li>\n",
       "\t<li>'income'</li>\n",
       "\t<li>'artsincollege'</li>\n",
       "\t<li>'hstype'</li>\n",
       "\t<li>'hssize'</li>\n",
       "\t<li>'hslocation'</li>\n",
       "\t<li>'hs_arts_freq'</li>\n",
       "\t<li>'hs_encouragement'</li>\n",
       "\t<li>'hs_required'</li>\n",
       "\t<li>'hs_fees'</li>\n",
       "\t<li>'so_childhood1'</li>\n",
       "\t<li>'so_childhood3'</li>\n",
       "\t<li>'so_childhood5'</li>\n",
       "\t<li>'sr_participated'</li>\n",
       "\t<li>'sr_highestdegreeplanned'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'ethnic\\_group'\n",
       "\\item 'sex'\n",
       "\\item 'school'\n",
       "\\item 'parented'\n",
       "\\item 'income'\n",
       "\\item 'artsincollege'\n",
       "\\item 'hstype'\n",
       "\\item 'hssize'\n",
       "\\item 'hslocation'\n",
       "\\item 'hs\\_arts\\_freq'\n",
       "\\item 'hs\\_encouragement'\n",
       "\\item 'hs\\_required'\n",
       "\\item 'hs\\_fees'\n",
       "\\item 'so\\_childhood1'\n",
       "\\item 'so\\_childhood3'\n",
       "\\item 'so\\_childhood5'\n",
       "\\item 'sr\\_participated'\n",
       "\\item 'sr\\_highestdegreeplanned'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'ethnic_group'\n",
       "2. 'sex'\n",
       "3. 'school'\n",
       "4. 'parented'\n",
       "5. 'income'\n",
       "6. 'artsincollege'\n",
       "7. 'hstype'\n",
       "8. 'hssize'\n",
       "9. 'hslocation'\n",
       "10. 'hs_arts_freq'\n",
       "11. 'hs_encouragement'\n",
       "12. 'hs_required'\n",
       "13. 'hs_fees'\n",
       "14. 'so_childhood1'\n",
       "15. 'so_childhood3'\n",
       "16. 'so_childhood5'\n",
       "17. 'sr_participated'\n",
       "18. 'sr_highestdegreeplanned'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"ethnic_group\"            \"sex\"                    \n",
       " [3] \"school\"                  \"parented\"               \n",
       " [5] \"income\"                  \"artsincollege\"          \n",
       " [7] \"hstype\"                  \"hssize\"                 \n",
       " [9] \"hslocation\"              \"hs_arts_freq\"           \n",
       "[11] \"hs_encouragement\"        \"hs_required\"            \n",
       "[13] \"hs_fees\"                 \"so_childhood1\"          \n",
       "[15] \"so_childhood3\"           \"so_childhood5\"          \n",
       "[17] \"sr_participated\"         \"sr_highestdegreeplanned\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "small_demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using key, ethnic_group, sex, school, parented, income, artsincollege, hstype, hssize, hslocation, hs_arts_freq, hs_encouragement, hs_required, hs_fees, so_childhood1, so_childhood3, so_childhood5, sr_participated, sr_highestdegreeplanned as id variables\n"
     ]
    }
   ],
   "source": [
    "    plotdata <- melt(na.omit(demodfpcs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No id variables; using all as measure variables\n"
     ]
    }
   ],
   "source": [
    "reshapedata <- melt(pcs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'pc'</li>\n",
       "\t<li>'ethnic_group'</li>\n",
       "\t<li>'sex'</li>\n",
       "\t<li>'school'</li>\n",
       "\t<li>'parented'</li>\n",
       "\t<li>'income'</li>\n",
       "\t<li>'artsincollege'</li>\n",
       "\t<li>'hstype'</li>\n",
       "\t<li>'hssize'</li>\n",
       "\t<li>'hslocation'</li>\n",
       "\t<li>'hs_arts_freq'</li>\n",
       "\t<li>'hs_encouragement'</li>\n",
       "\t<li>'hs_required'</li>\n",
       "\t<li>'hs_fees'</li>\n",
       "\t<li>'so_childhood1'</li>\n",
       "\t<li>'so_childhood3'</li>\n",
       "\t<li>'so_childhood5'</li>\n",
       "\t<li>'sr_participated'</li>\n",
       "\t<li>'sr_highestdegreeplanned'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'pc'\n",
       "\\item 'ethnic\\_group'\n",
       "\\item 'sex'\n",
       "\\item 'school'\n",
       "\\item 'parented'\n",
       "\\item 'income'\n",
       "\\item 'artsincollege'\n",
       "\\item 'hstype'\n",
       "\\item 'hssize'\n",
       "\\item 'hslocation'\n",
       "\\item 'hs\\_arts\\_freq'\n",
       "\\item 'hs\\_encouragement'\n",
       "\\item 'hs\\_required'\n",
       "\\item 'hs\\_fees'\n",
       "\\item 'so\\_childhood1'\n",
       "\\item 'so\\_childhood3'\n",
       "\\item 'so\\_childhood5'\n",
       "\\item 'sr\\_participated'\n",
       "\\item 'sr\\_highestdegreeplanned'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'pc'\n",
       "2. 'ethnic_group'\n",
       "3. 'sex'\n",
       "4. 'school'\n",
       "5. 'parented'\n",
       "6. 'income'\n",
       "7. 'artsincollege'\n",
       "8. 'hstype'\n",
       "9. 'hssize'\n",
       "10. 'hslocation'\n",
       "11. 'hs_arts_freq'\n",
       "12. 'hs_encouragement'\n",
       "13. 'hs_required'\n",
       "14. 'hs_fees'\n",
       "15. 'so_childhood1'\n",
       "16. 'so_childhood3'\n",
       "17. 'so_childhood5'\n",
       "18. 'sr_participated'\n",
       "19. 'sr_highestdegreeplanned'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"pc\"                      \"ethnic_group\"           \n",
       " [3] \"sex\"                     \"school\"                 \n",
       " [5] \"parented\"                \"income\"                 \n",
       " [7] \"artsincollege\"           \"hstype\"                 \n",
       " [9] \"hssize\"                  \"hslocation\"             \n",
       "[11] \"hs_arts_freq\"            \"hs_encouragement\"       \n",
       "[13] \"hs_required\"             \"hs_fees\"                \n",
       "[15] \"so_childhood1\"           \"so_childhood3\"          \n",
       "[17] \"so_childhood5\"           \"sr_participated\"        \n",
       "[19] \"sr_highestdegreeplanned\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
